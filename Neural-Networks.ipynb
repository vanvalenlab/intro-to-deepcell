{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks\n",
    "\n",
    "First, set up the environment by installing the required packages and importing the necessary functions and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras numpy tensorflow sklearn scipy\n",
    "# conda install keras numpy tensorflow sklearn scipy\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and prepare the data\n",
    "\n",
    "For this introduction, the classic MNIST dataset of hand-drawn digits is used.  Download the data, reshape it if necessary, and normalize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# load the data, split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image number: 39841\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AxesSubplot' object has no attribute 'ravel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-754e96203932>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msharey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AxesSubplot' object has no attribute 'ravel'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the raw data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = np.random.randint(low=0, high=X_train.shape[0])\n",
    "print('Image number:', index)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=1, figsize=(15, 15), sharex=True, sharey=True)\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(X_train[index])\n",
    "ax[0].set_title('Source Image')\n",
    "\n",
    "ax[1].imshow(y_train[index])\n",
    "ax[1].set_title('Label Image')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "y_train shape: (60000,)\n",
      "First 10 values of y_train: [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# Reshape data if necessary\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1) # (batches, rows, cols, channels)\n",
    "\n",
    "# normalize the data: set pixel values to be in range [0, 1]\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.\n",
    "X_test /= 255.\n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('First 10 values of y_train:', y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Classifier\n",
    "\n",
    "First, try using a linear classifier with the MNIST data.  Below is an implmentation of a Support Vector Machine from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       980\n",
      "           1       0.96      0.98      0.97      1135\n",
      "           2       0.93      0.89      0.91      1032\n",
      "           3       0.89      0.91      0.90      1010\n",
      "           4       0.92      0.93      0.92       982\n",
      "           5       0.89      0.86      0.88       892\n",
      "           6       0.94      0.95      0.94       958\n",
      "           7       0.92      0.92      0.92      1028\n",
      "           8       0.88      0.87      0.87       974\n",
      "           9       0.90      0.89      0.89      1009\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n",
      "Accuracy Score: 0.9183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Our current shape is (batches, rows, cols, channels) but SVC expects (batches, pixels)\n",
    "X_train_reshaped = np.reshape(X_train, (X_train.shape[0], X_train.shape[1]*X_train.shape[2]))\n",
    "X_test_reshaped = np.reshape(X_test, (X_test.shape[0], X_test.shape[1]*X_test.shape[2]))\n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "model.fit(X_train_reshaped, y_train)\n",
    "\n",
    "predictions = model.predict(X_test_reshaped)\n",
    "print(classification_report(y_test, predictions))\n",
    "print('Accuracy Score:', accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "Let's compare our linear classifier results with simple neural networks using Keras.\n",
    "\n",
    "First, convert the class vectors to binary class matrices or \"one-hot encode\" the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape: (60000, 10)\n",
      "y_test shape: (10000, 10)\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Using the keras to_categorical function to one-hot encode the data\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Network\n",
    "\n",
    "First, a basic one-layer example. *(Using the functional model API)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.5879 - acc: 0.8467 - val_loss: 0.3817 - val_acc: 0.8989\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.3752 - acc: 0.8971 - val_loss: 0.3384 - val_acc: 0.9090\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.3435 - acc: 0.9046 - val_loss: 0.3169 - val_acc: 0.9120\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.3269 - acc: 0.9087 - val_loss: 0.3072 - val_acc: 0.9139\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.3163 - acc: 0.9118 - val_loss: 0.3006 - val_acc: 0.9174\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=input_shape)\n",
    "model = Sequential()\n",
    "flat = Flatten()(inputs)\n",
    "dense = Dense(10, activation='softmax')(flat) # output is softmax(dot(X, W) + bias)\n",
    "model = Model(inputs=inputs, outputs=dense)\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=SGD(momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "loss = model.fit(X_train, y_train,\n",
    "                 batch_size=128,\n",
    "                 epochs=5,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network\n",
    "\n",
    "5 epochs yield results comparable to the linear classifier, but the neural network can definitely be improved.  Below is a common pattern of Convolutions, Pooling, Dropout, and Dense layers.  [Read more about these layer types on Wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network#Design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 87s 1ms/sample - loss: 0.3229 - acc: 0.9030 - val_loss: 0.1016 - val_acc: 0.9696\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 94s 2ms/sample - loss: 0.0937 - acc: 0.9718 - val_loss: 0.0634 - val_acc: 0.9795\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 90s 2ms/sample - loss: 0.0635 - acc: 0.9801 - val_loss: 0.0529 - val_acc: 0.9823\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0488 - acc: 0.9848 - val_loss: 0.0438 - val_acc: 0.9849\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 82s 1ms/sample - loss: 0.0400 - acc: 0.9877 - val_loss: 0.0388 - val_acc: 0.9876\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 32 3x3 filters (extracting 5x5-pixel subregions), with ReLU activation\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))# Apply max filter to every 2x2 patch\n",
    "model.add(Dropout(0.25)) # Drop 25% of inputs to prevent overfitting\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=SGD(momentum=0.9, nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "loss = model.fit(X_train, y_train,\n",
    "                 batch_size=128,\n",
    "                 epochs=5,\n",
    "                 verbose=1,\n",
    "                 validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
